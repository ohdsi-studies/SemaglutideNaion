
@misc{noauthor_ohdsistrategus_2024,
	title = {{OHDSI}/{Strategus}},
	url = {https://github.com/OHDSI/Strategus},
	abstract = {[Under development] An R packages for coordinating and executing analytics using HADES modules},
	urldate = {2023-04-29},
	publisher = {Observational Health Data Sciences and Informatics},
	month = jun,
	year = {2024},
	note = {original-date: 2022-03-24T15:08:20Z},
}

@incollection{schuemie_health-analytics_2024,
	title = {Health-{Analytics} {Data} to {Evidence} {Suite} ({HADES}): {Open}-{Source} {Software} for {Observational} {Research}},
	shorttitle = {Health-{Analytics} {Data} to {Evidence} {Suite} ({HADES})},
	url = {https://ebooks.iospress.nl/doi/10.3233/SHTI231108},
	urldate = {2024-08-08},
	publisher = {IOS Press},
	author = {Schuemie, Martijn and Reps, Jenna and Black, Adam and Defalco, Frank and Evans, Lee and Fridgeirsson, Egill and Gilbert, James P. and Knoll, Chris and Lavallee, Martin and Rao, Gowtham A. and Rijnbeek, Peter and Sadowski, Katy and Sena, Anthony and Swerdel, Joel and Williams, Ross D. and Suchard, Marc},
	year = {2024},
	doi = {10.3233/SHTI231108},
	pages = {966--970},
	file = {Full Text PDF:/Users/erik/Zotero/storage/JKRHDT6E/Schuemie et al. - 2024 - Health-Analytics Data to Evidence Suite (HADES) O.pdf:application/pdf},
}

@article{barkmeier_comparative_2024,
	title = {Comparative {Effectiveness} of {Glucagon}-{Like} {Peptide}-1 {Receptor} {Agonists}, {Sodium}-{Glucose} {Cotransporter} 2 {Inhibitors}, {Dipeptidyl} {Peptidase}-4 {Inhibitors}, and {Sulfonylureas} for {Sight}-{Threatening} {Diabetic} {Retinopathy}},
	url = {https://www.sciencedirect.com/science/article/pii/S246865302400229X?casa_token=g0OKdr9FZSEAAAAA:N_XVHHruQwdscyp77Qd0B1d_r-u_UYB37qV_68jZpYGRigfUiQSgMLDxRT5LcVBoZbZFN-ss},
	doi = {10.1016/j.oret.2024.05.003},
	urldate = {2024-08-08},
	journal = {Ophthalmology Retina},
	author = {Barkmeier, Andrew J. and Herrin, Jeph and Swarna, Kavya Sindhu and Deng, Yihong and Polley, Eric C. and Umpierrez, Guillermo E. and Galindo, Rodolfo J. and Ross, Joseph S. and Mickelson, Mindy M. and McCoy, Rozalina G.},
	year = {2024},
	note = {Publisher: Elsevier},
	file = {Available Version (via Google Scholar):/Users/erik/Zotero/storage/GEGP8ECB/S246865302400229X.html:text/html},
}

@article{albert_glucagon-like_2023,
	title = {Glucagon-like peptide 1-receptor agonists and {A1c}: good for the heart but less so for the eyes?},
	volume = {17},
	shorttitle = {Glucagon-like peptide 1-receptor agonists and {A1c}},
	url = {https://www.sciencedirect.com/science/article/pii/S1871402122003137?casa_token=R8Qw9BLOA98AAAAA:l8BNLl5HuAtHzXL3N1LUjEy1j83aoCfwqbHeq3yHevOqT7FwwlyOm9Iynp5D4VSKgWQxgHdy},
	doi = {10.1016/j.dsx.2022.102696},
	number = {1},
	urldate = {2024-08-08},
	journal = {Diabetes \& Metabolic Syndrome: Clinical Research \& Reviews},
	author = {Albert, Stewart G. and Wood, Emily M. and Ahir, Vaishaliben},
	year = {2023},
	note = {Publisher: Elsevier},
	pages = {102696},
	file = {Available Version (via Google Scholar):/Users/erik/Zotero/storage/98NU6PT7/S1871402122003137.html:text/html},
}

@article{hathaway_risk_2024,
	title = {Risk of nonarteritic anterior ischemic optic neuropathy in patients prescribed semaglutide},
	url = {https://jamanetwork.com/journals/jamaophthalmology/article-abstract/2820255},
	doi = {10.1001/jamaophthalmol.2024.2296},
	urldate = {2024-08-08},
	journal = {JAMA ophthalmology},
	author = {Hathaway, Jimena Tatiana and Shah, Madhura P. and Hathaway, David B. and Zekavat, Seyedeh Maryam and Krasniqi, Drenushe and Gittinger, John W. and Cestari, Dean and Mallery, Robert and Abbasi, Bardia and Bouffard, Marc},
	year = {2024},
	file = {Available Version (via Google Scholar):/Users/erik/Zotero/storage/8I7A4I5P/2820255.html:text/html},
}

@article{joo_effect_2024,
	title = {The {Effect} of {Glucagon}-{Like} {Peptide}-1 {Receptor} {Agonists} on {Diabetic} {Retinopathy} at a {Tertiary} {Care} {Center}},
	volume = {4},
	issn = {2666-9145},
	url = {https://www.ophthalmologyscience.org/article/S2666-9145(24)00083-6/fulltext},
	doi = {10.1016/j.xops.2024.100547},
	language = {English},
	number = {6},
	urldate = {2024-08-08},
	journal = {Ophthalmology Science},
	author = {Joo, Julia H. and Sharma, Neha and Shaia, Jacqueline and Wu, Anna K. and Skugor, Mario and Singh, Rishi P. and Rachitskaya, Aleksandra V.},
	month = nov,
	year = {2024},
	note = {Publisher: Elsevier},
	keywords = {BMI, body mass index, cardiovascular outcome trial, CI, confidence interval, CVOT, Diabetes mellitus, diabetic retinopathy, Diabetic retinopathy, DR, Early worsening, GLP-1 receptor agonists, GLP-1RA, glucagon-like peptide-1 agonists, HbA1C, hemoglobin A1c, ICD, International Classification of Diseases, odds ratio, OR, panretinal photocoagulation, pars plana vitrectomy, PDR, PPV, proliferative diabetic retinopathy, PRP, SD, SGLT-2 inhibitors, SGLT-2I, standard deviation},
	file = {Full Text PDF:/Users/erik/Zotero/storage/EYXM33KB/Joo et al. - 2024 - The Effect of Glucagon-Like Peptide-1 Receptor Ago.pdf:application/pdf},
}

@article{hayreh_nonarteritic_2008,
	title = {Nonarteritic anterior ischemic optic neuropathy: natural history of visual outcome},
	volume = {115},
	issn = {1549-4713},
	shorttitle = {Nonarteritic anterior ischemic optic neuropathy},
	doi = {10.1016/j.ophtha.2007.05.027},
	abstract = {OBJECTIVE: To investigate systematically the natural history of visual outcome in nonarteritic anterior ischemic optic neuropathy (NAION).
DESIGN: Cohort study.
PARTICIPANTS: Three hundred forty consecutive untreated patients (386 eyes) with NAION, first seen in our clinic from 1973 to 2000.
METHODS: At first visit, all patients gave a detailed ophthalmic and medical history and underwent a comprehensive ophthalmic evaluation. Visual evaluation was done by recording visual acuity, using the Snellen visual acuity chart, and visual fields with a Goldmann perimeter. The same ophthalmic evaluation was performed at each follow-up visit.
MAIN OUTCOME MEASURES: Natural history of visual acuity and visual field outcome in NAION.
RESULTS: Of the 386 eyes, 332 had 8 weeks or more of follow-up from the initial visit. At the initial visit, in eyes seen {\textless} or =2 weeks from onset of symptoms, 49\% had visual acuity of {\textgreater} or =20/30 and 23\% had {\textless} or =20/200; in these eyes, 38\% had minimal to mild visual field defect and 43\% marked to severe defect. In those who were first seen {\textless} or =2 weeks after onset with visual acuity {\textless} or =20/70, there was improvement in 41\% at 6 months and in 42\% at 1 year after the initial visit. Two years after the initial visit, there was deterioration in 9\% of eyes with initial visual acuity of {\textgreater} or =20/60, and in 18\% of those with initial visual acuity of {\textless} or =20/70. In those who were first seen {\textless} or =2 weeks of onset with moderate to severe visual field defect, there was improvement in 26\% at 6 months and 27\% at 1 year after the initial visit. Two years after the initial visit, 27\% of eyes with initial minimal to mild field defects showed worsening, as did 19\% of those with moderate to severe defects.
CONCLUSIONS: About half of the eyes with NAION presented with almost normal visual acuity (20/15 to 20/30) at the initial visit. Thus, the presence of normal visual acuity does not rule out NAION. Visual acuity and visual fields showed improvement or further deterioration mainly up to 6 months, with no significant change after that.},
	language = {eng},
	number = {2},
	journal = {Ophthalmology},
	author = {Hayreh, Sohan Singh and Zimmerman, M. Bridget},
	month = feb,
	year = {2008},
	pmid = {17698200},
	pmcid = {PMC2782939},
	keywords = {Arteritis, Cohort Studies, Female, Follow-Up Studies, Humans, Male, Middle Aged, Optic Neuropathy, Ischemic, Papilledema, Vision Disorders, Visual Acuity, Visual Field Tests, Visual Fields},
	pages = {298--305.e2},
	file = {Accepted Version:/Users/erik/Zotero/storage/8G9QW32S/Hayreh and Zimmerman - 2008 - Nonarteritic anterior ischemic optic neuropathy n.pdf:application/pdf},
}

@article{hui_glucagon-like_2024,
	title = {Glucagon-like {Peptide} 1 {Receptor} {Agonist} use and the effect on diabetic retinopathy: {An} uncertain relationship},
	volume = {178},
	issn = {1873-5169},
	shorttitle = {Glucagon-like {Peptide} 1 {Receptor} {Agonist} use and the effect on diabetic retinopathy},
	doi = {10.1016/j.peptides.2024.171240},
	abstract = {Glucagon-like Peptide 1 Receptor Agonists (GLP-1 RAs) are a group of relatively novel medications for the treatment of diabetes mellitus. These medications can mimic the naturally occurring incretins of the body, which promote the release of insulin in response to hyperglycaemia. The anti-glycaemic effects of these medications can be profound and carry other metabolic benefits such as promoting weight loss. Clinical trials have shown GLP-1 RAs are safe to use from a cardiovascular perspective. However, some trials have suggested a link between GLP-1 RA use and worsening diabetic retinopathy. The conclusions surrounding this link are poorly established as data is drawn primarily from cardiovascular outcome trials. If an association does exist, a possible explanation might be the observed phenomenon of early worsening diabetic retinopathy with rapid correction of hyperglycaemic states. Trials which look at diabetic retinopathy as a primary outcome in relation to use of GLP-1 RAs are sparse and warrant investigation given the growing use of this group of medications. Therefore currently, it is uncertain what effect, beneficial or adverse, GLP-1 RA use has on diabetic retinopathy. This article provides an overview of GLP-1 RA use as a treatment for diabetes mellitus and the current understanding of their relationship with diabetic retinopathy.},
	language = {eng},
	journal = {Peptides},
	author = {Hui, Benjamin T. K. and Yeong, Jian Lee and Peto, Tunde and Willoughby, Colin E.},
	month = aug,
	year = {2024},
	pmid = {38705472},
	keywords = {Diabetes mellitus, Diabetic retinopathy, Humans, Diabetes Mellitus, Type 2, Diabetic Retinopathy, Glucagon-like Peptide 1 Receptor Agonists, Glucagon-Like Peptide-1 Receptor, Hypoglycemic Agents},
	pages = {171240},
}

@article{mollan_semaglutide_2024,
	title = {Semaglutide and {Nonarteritic} {Anterior} {Ischemic} {Optic} {Neuropathy}},
	issn = {2168-6173},
	doi = {10.1001/jamaophthalmol.2024.2514},
	language = {eng},
	journal = {JAMA ophthalmology},
	author = {Mollan, Susan P.},
	month = jul,
	year = {2024},
	pmid = {38958953},
}

@article{cox_regression_1972,
	title = {Regression {Models} and {Life}-{Tables}},
	volume = {34},
	copyright = {© 1972 The Authors},
	issn = {2517-6161},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1972.tb00899.x},
	doi = {10.1111/j.2517-6161.1972.tb00899.x},
	abstract = {The analysis of censored failure times is considered. It is assumed that on each individual are available values of one or more explanatory variables. The hazard function (age-specific failure rate) is taken to be a function of the explanatory variables and unknown regression coefficients multiplied by an arbitrary and unknown function of time. A conditional likelihood is obtained, leading to inferences about the unknown regression coefficients. Some generalizations are outlined.},
	language = {en},
	number = {2},
	urldate = {2024-08-08},
	journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
	author = {Cox, D. R.},
	year = {1972},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.2517-6161.1972.tb00899.x},
	keywords = {accelerated life tests, age-specific failure rate, asymptotic theory, censored data, conditional inference, hazard function, life table, medical applications, product limit estimate, regression, reliability theory, two-sample rank tests},
	pages = {187--202},
	file = {Snapshot:/Users/erik/Zotero/storage/2RNVJQAX/j.2517-6161.1972.tb00899.html:text/html},
}

@article{tian_evaluating_2018,
	title = {Evaluating large-scale propensity score performance through real-world and synthetic data experiments},
	volume = {47},
	issn = {1464-3685},
	doi = {10.1093/ije/dyy120},
	abstract = {BACKGROUND: Propensity score adjustment is a popular approach for confounding control in observational studies. Reliable frameworks are needed to determine relative propensity score performance in large-scale studies, and to establish optimal propensity score model selection methods.
METHODS: We detail a propensity score evaluation framework that includes synthetic and real-world data experiments. Our synthetic experimental design extends the 'plasmode' framework and simulates survival data under known effect sizes, and our real-world experiments use a set of negative control outcomes with presumed null effect sizes. In reproductions of two published cohort studies, we compare two propensity score estimation methods that contrast in their model selection approach: L1-regularized regression that conducts a penalized likelihood regression, and the 'high-dimensional propensity score' (hdPS) that employs a univariate covariate screen. We evaluate methods on a range of outcome-dependent and outcome-independent metrics.
RESULTS: L1-regularization propensity score methods achieve superior model fit, covariate balance and negative control bias reduction compared with the hdPS. Simulation results are mixed and fluctuate with simulation parameters, revealing a limitation of simulation under the proportional hazards framework. Including regularization with the hdPS reduces commonly reported non-convergence issues but has little effect on propensity score performance.
CONCLUSIONS: L1-regularization incorporates all covariates simultaneously into the propensity score model and offers propensity score performance superior to the hdPS marginal screen.},
	language = {eng},
	number = {6},
	journal = {International Journal of Epidemiology},
	author = {Tian, Yuxi and Schuemie, Martijn J. and Suchard, Marc A.},
	month = dec,
	year = {2018},
	pmid = {29939268},
	pmcid = {PMC6280944},
	keywords = {Humans, Algorithms, Bias, Confounding Factors, Epidemiologic, Logistic Models, Observational Studies as Topic, Propensity Score, Research Design, Sample Size},
	pages = {2005--2014},
	file = {Full Text:/Users/erik/Zotero/storage/P5363RL8/Tian et al. - 2018 - Evaluating large-scale propensity score performanc.pdf:application/pdf},
}

@article{sharma_semaglutide_2022,
	title = {Semaglutide and the risk of diabetic retinopathy-current perspective},
	volume = {36},
	issn = {1476-5454},
	doi = {10.1038/s41433-021-01741-5},
	language = {eng},
	number = {1},
	journal = {Eye (London, England)},
	author = {Sharma, Ashish and Parachuri, Nikulaa and Kumar, Nilesh and Saboo, Bharat and Tripathi, Hridaya Nath and Kuppermann, Baruch D. and Bandello, Francesco},
	month = jan,
	year = {2022},
	pmid = {34373613},
	pmcid = {PMC8727607},
	keywords = {Humans, Diabetes Mellitus, Type 2, Diabetic Retinopathy, Hypoglycemic Agents, Glucagon-Like Peptides},
	pages = {10--11},
	file = {Full Text:/Users/erik/Zotero/storage/7FIDJNMC/Sharma et al. - 2022 - Semaglutide and the risk of diabetic retinopathy-c.pdf:application/pdf},
}

@article{stevens_long-term_2024,
	title = {Long-term use of semaglutide and risk of diabetic retinopathy progression},
	volume = {15},
	issn = {2666-3961},
	url = {https://www.sciencedirect.com/science/article/pii/S2666396124000128},
	doi = {10.1016/j.endmts.2024.100168},
	abstract = {Objective
Concerns exist about semaglutide, potentially worsening sight-threatening diabetic retinopathy (DR) in individuals with diabetes. This study aimed to explore the association between semaglutide and the risk of DR progression over three years in patients with type 2 diabetes (T2D). It is hypothesized that any observed deterioration in DR among T2D patients following semaglutide use would be temporary and unrelated to long-term progression.
Methods
Retrospective data analysis identified 4086 patients with T2D and DR by ICD-10 codes in a Retina only practice from January to June 2020. Use of semaglutide was found in 116 patients. Inclusion criteria included at least 1 year of semaglutide use and documentation of level of non-proliferative (NPDR) and proliferative (PDR) retinopathy, visual acuity (VA) and Central Subfield Thickness (CST).
Results
87 patients meeting the eligibility criteria, ranging in age from 38 to 84 years (mean age of 62.4 years), and having an average duration of semaglutide usage of approximately 2.9 years. Gender distribution included 58.6 \% male and 41.4 \% female patients, with 83.9 \% Caucasian, 11.5 \% Black, and 10.3 \% Hispanic backgrounds. The baseline HbA1c level averaged 7.6 \%, ranging from 5.9 \% to 10.9 \%, with a standard deviation of 1.1. The last self-reported HbA1c level averaged 7.4 \%, ranging from 5.2 \% to 14 \%, with a standard deviation of 1.5. Baseline DR severity correlated with progression risk: 2.7 \% for DRSS level ≤ 43, 28 \% for levels 47/53, and 45 \% for baseline PDR. Patients required an average of 12.6 intravitreal injections. Visual acuity remained stable for 72.4 \% of patients, with 16.1 \% experiencing a loss and 11.5 \% achieving improvement.
Conclusion
Semaglutide use was not associated with increased risk of progression of DR, visual loss, or an increased number of intravitreal injections over a 3-year period of time.},
	urldate = {2024-08-08},
	journal = {Endocrine and Metabolic Science},
	author = {Stevens, Henry and de la Paz, Max and Cooper, Blake and Bhattacharya, Rajib},
	month = jun,
	year = {2024},
	keywords = {Diabetic retinopathy progression, Ocular complications, Retrospective study, Semaglutide, Type 2 diabetes},
	pages = {100168},
	file = {ScienceDirect Snapshot:/Users/erik/Zotero/storage/CDIMDGYJ/S2666396124000128.html:text/html},
}

@article{american_diabetes_association_professional_practice_committee_9_2021,
	title = {9. {Pharmacologic} {Approaches} to {Glycemic} {Treatment}: {Standards} of {Medical} {Care} in {Diabetes}—2022},
	volume = {45},
	issn = {0149-5992},
	shorttitle = {9. {Pharmacologic} {Approaches} to {Glycemic} {Treatment}},
	url = {https://doi.org/10.2337/dc22-S009},
	doi = {10.2337/dc22-S009},
	abstract = {The American Diabetes Association (ADA) “Standards of Medical Care in Diabetes” includes the ADA’s current clinical practice recommendations and is intended to provide the components of diabetes care, general treatment goals and guidelines, and tools to evaluate quality of care. Members of the ADA Professional Practice Committee, a multidisciplinary expert committee (https://doi.org/10.2337/dc22-SPPC), are responsible for updating the Standards of Care annually, or more frequently as warranted. For a detailed description of ADA standards, statements, and reports, as well as the evidence-grading system for ADA’s clinical practice recommendations, please refer to the Standards of Care Introduction (https://doi.org/10.2337/dc22-SINT). Readers who wish to comment on the Standards of Care are invited to do so at professional.diabetes.org/SOC.},
	number = {Supplement\_1},
	urldate = {2024-08-08},
	journal = {Diabetes Care},
	author = {{American Diabetes Association Professional Practice Committee}},
	month = dec,
	year = {2021},
	pages = {S125--S143},
	file = {Full Text PDF:/Users/erik/Zotero/storage/MDWM5359/American Diabetes Association Professional Practice Committee - 2021 - 9. Pharmacologic Approaches to Glycemic Treatment.pdf:application/pdf;Snapshot:/Users/erik/Zotero/storage/X5UQNKHH/9-Pharmacologic-Approaches-to-Glycemic-Treatment.html:text/html},
}

@article{perkovic_effects_2024,
	title = {Effects of {Semaglutide} on {Chronic} {Kidney} {Disease} in {Patients} with {Type} 2 {Diabetes}},
	volume = {391},
	copyright = {http://www.nejmgroup.org/legal/terms-of-use.htm},
	issn = {0028-4793, 1533-4406},
	url = {http://www.nejm.org/doi/10.1056/NEJMoa2403347},
	doi = {10.1056/NEJMoa2403347},
	language = {en},
	number = {2},
	urldate = {2024-08-08},
	journal = {New England Journal of Medicine},
	author = {Perkovic, Vlado and Tuttle, Katherine R. and Rossing, Peter and Mahaffey, Kenneth W. and Mann, Johannes F.E. and Bakris, George and Baeres, Florian M.M. and Idorn, Thomas and Bosch-Traberg, Heidrun and Lausvig, Nanna Leonora and Pratley, Richard},
	month = jul,
	year = {2024},
	pages = {109--121},
}

@article{marso_semaglutide_2016,
	title = {Semaglutide and {Cardiovascular} {Outcomes} in {Patients} with {Type} 2 {Diabetes}},
	volume = {375},
	issn = {0028-4793, 1533-4406},
	url = {http://www.nejm.org/doi/10.1056/NEJMoa1607141},
	doi = {10.1056/NEJMoa1607141},
	language = {en},
	number = {19},
	urldate = {2024-08-08},
	journal = {New England Journal of Medicine},
	author = {Marso, Steven P. and Bain, Stephen C. and Consoli, Agostino and Eliaschewitz, Freddy G. and Jódar, Esteban and Leiter, Lawrence A. and Lingvay, Ildiko and Rosenstock, Julio and Seufert, Jochen and Warren, Mark L. and Woo, Vincent and Hansen, Oluf and Holst, Anders G. and Pettersson, Jonas and Vilsbøll, Tina},
	month = nov,
	year = {2016},
	pages = {1834--1844},
	file = {Available Version (via Google Scholar):/Users/erik/Zotero/storage/9Q7AH5MD/Marso et al. - 2016 - Semaglutide and Cardiovascular Outcomes in Patient.pdf:application/pdf},
}

@article{schuemie_empirical_2018,
	title = {Empirical confidence interval calibration for population-level effect estimation studies in observational healthcare data},
	volume = {115},
	issn = {1091-6490},
	doi = {10.1073/pnas.1708282114},
	abstract = {Observational healthcare data, such as electronic health records and administrative claims, offer potential to estimate effects of medical products at scale. Observational studies have often been found to be nonreproducible, however, generating conflicting results even when using the same database to answer the same question. One source of discrepancies is error, both random caused by sampling variability and systematic (for example, because of confounding, selection bias, and measurement error). Only random error is typically quantified but converges to zero as databases become larger, whereas systematic error persists independent from sample size and therefore, increases in relative importance. Negative controls are exposure-outcome pairs, where one believes no causal effect exists; they can be used to detect multiple sources of systematic error, but interpreting their results is not always straightforward. Previously, we have shown that an empirical null distribution can be derived from a sample of negative controls and used to calibrate P values, accounting for both random and systematic error. Here, we extend this work to calibration of confidence intervals (CIs). CIs require positive controls, which we synthesize by modifying negative controls. We show that our CI calibration restores nominal characteristics, such as 95\% coverage of the true effect size by the 95\% CI. We furthermore show that CI calibration reduces disagreement in replications of two pairs of conflicting observational studies: one related to dabigatran, warfarin, and gastrointestinal bleeding and one related to selective serotonin reuptake inhibitors and upper gastrointestinal bleeding. We recommend CI calibration to improve reproducibility of observational studies.},
	language = {eng},
	number = {11},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Schuemie, Martijn J. and Hripcsak, George and Ryan, Patrick B. and Madigan, David and Suchard, Marc A.},
	month = mar,
	year = {2018},
	pmid = {29531023},
	pmcid = {PMC5856503},
	keywords = {Humans, Bias, Observational Studies as Topic, Research Design, calibration, Calibration, Confidence Intervals, Health Services Research, observational studies, systematic error},
	pages = {2571--2577},
	file = {Full Text:/Users/erik/Zotero/storage/NNCAANM6/Schuemie et al. - 2018 - Empirical confidence interval calibration for popu.pdf:application/pdf},
}

@article{schuemie_robust_2016,
	title = {Robust empirical calibration of p‐values using observational data},
	volume = {35},
	issn = {0277-6715},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5108459/},
	doi = {10.1002/sim.6977},
	number = {22},
	urldate = {2024-08-20},
	journal = {Statistics in Medicine},
	author = {Schuemie, Martijn J. and Hripcsak, George and Ryan, Patrick B. and Madigan, David and Suchard, Marc A.},
	month = sep,
	year = {2016},
	pmid = {27592566},
	pmcid = {PMC5108459},
	pages = {3883--3888},
	file = {PubMed Central Full Text PDF:/Users/erik/Zotero/storage/KIBZ6UT2/Schuemie et al. - 2016 - Robust empirical calibration of p‐values using obs.pdf:application/pdf},
}

@article{voss_accuracy_2017,
	title = {Accuracy of an automated knowledge base for identifying drug adverse reactions},
	volume = {66},
	issn = {1532-0480},
	doi = {10.1016/j.jbi.2016.12.005},
	abstract = {INTRODUCTION: Drug safety researchers seek to know the degree of certainty with which a particular drug is associated with an adverse drug reaction. There are different sources of information used in pharmacovigilance to identify, evaluate, and disseminate medical product safety evidence including spontaneous reports, published peer-reviewed literature, and product labels. Automated data processing and classification using these evidence sources can greatly reduce the manual curation currently required to develop reference sets of positive and negative controls (i.e. drugs that cause adverse drug events and those that do not) to be used in drug safety research.
METHODS: In this paper we explore a method for automatically aggregating disparate sources of information together into a single repository, developing a predictive model to classify drug-adverse event relationships, and applying those predictions to a real world problem of identifying negative controls for statistical method calibration.
RESULTS: Our results showed high predictive accuracy for the models combining all available evidence, with an area under the receiver-operator curve of ⩾0.92 when tested on three manually generated lists of drugs and conditions that are known to either have or not have an association with an adverse drug event.
CONCLUSIONS: Results from a pilot implementation of the method suggests that it is feasible to develop a scalable alternative to the time-and-resource-intensive, manual curation exercise previously applied to develop reference sets of positive and negative controls to be used in drug safety research.},
	language = {eng},
	journal = {Journal of Biomedical Informatics},
	author = {Voss, E. A. and Boyce, R. D. and Ryan, P. B. and van der Lei, J. and Rijnbeek, P. R. and Schuemie, M. J.},
	month = feb,
	year = {2017},
	pmid = {27993747},
	pmcid = {PMC5316295},
	keywords = {Humans, Adverse drug reaction, Adverse Drug Reaction Reporting Systems, Drug-Related Side Effects and Adverse Reactions, Electronic Data Processing, Health outcome, Knowledge base, Knowledge Bases, Machine-learning experiment, Pharmacovigilance},
	pages = {72--81},
	file = {Accepted Version:/Users/erik/Zotero/storage/4CDIP3S3/Voss et al. - 2017 - Accuracy of an automated knowledge base for identi.pdf:application/pdf},
}

@article{schuemie_how_2020,
	title = {How {Confident} {Are} {We} about {Observational} {Findings} in {Healthcare}: {A} {Benchmark} {Study}},
	volume = {2},
	issn = {2644-2353},
	shorttitle = {How {Confident} {Are} {We} about {Observational} {Findings} in {Healthcare}},
	doi = {10.1162/99608f92.147cc28e},
	abstract = {Healthcare professionals increasingly rely on observational healthcare data, such as administrative claims and electronic health records, to estimate the causal effects of interventions. However, limited prior studies raise concerns about the real-world performance of the statistical and epidemiological methods that are used. We present the "OHDSI Methods Benchmark" that aims to evaluate the performance of effect estimation methods on real data. The benchmark comprises a gold standard, a set of metrics, and a set of open source software tools. The gold standard is a collection of real negative controls (drug-outcome pairs where no causal effect appears to exist) and synthetic positive controls (drug-outcome pairs that augment negative controls with simulated causal effects). We apply the benchmark using four large healthcare databases to evaluate methods commonly used in practice: the new-user cohort, self-controlled cohort, case-control, case-crossover, and self-controlled case series designs. The results confirm the concerns about these methods, showing that for most methods the operating characteristics deviate considerably from nominal levels. For example, in most contexts, only half of the 95\% confidence intervals we calculated contain the corresponding true effect size. We previously developed an "empirical calibration" procedure to restore these characteristics and we also evaluate this procedure. While no one method dominates, self-controlled methods such as the empirically calibrated self-controlled case series perform well across a wide range of scenarios.},
	language = {eng},
	number = {1},
	journal = {Harvard Data Science Review},
	author = {Schuemie, Martijn J. and Cepeda, M. Soledad and Suchard, Marc A. and Yang, Jianxiao and Tian, Yuxi and Schuler, Alejandro and Ryan, Patrick B. and Madigan, David and Hripcsak, George},
	year = {2020},
	pmid = {33367288},
	pmcid = {PMC7755157},
	keywords = {causal effect estimation, evaluation, methods, observational research},
	file = {Full Text:/Users/erik/Zotero/storage/FTJSX8CN/Schuemie et al. - 2020 - How Confident Are We about Observational Findings .pdf:application/pdf},
}

@article{schuemie_improving_2018,
	title = {Improving reproducibility by using high-throughput observational studies with empirical calibration},
	volume = {376},
	issn = {1471-2962},
	doi = {10.1098/rsta.2017.0356},
	abstract = {Concerns over reproducibility in science extend to research using existing healthcare data; many observational studies investigating the same topic produce conflicting results, even when using the same data. To address this problem, we propose a paradigm shift. The current paradigm centres on generating one estimate at a time using a unique study design with unknown reliability and publishing (or not) one estimate at a time. The new paradigm advocates for high-throughput observational studies using consistent and standardized methods, allowing evaluation, calibration and unbiased dissemination to generate a more reliable and complete evidence base. We demonstrate this new paradigm by comparing all depression treatments for a set of outcomes, producing 17 718 hazard ratios, each using methodology on par with current best practice. We furthermore include control hypotheses to evaluate and calibrate our evidence generation process. Results show good transitivity and consistency between databases, and agree with four out of the five findings from clinical trials. The distribution of effect size estimates reported in the literature reveals an absence of small or null effects, with a sharp cut-off at p = 0.05. No such phenomena were observed in our results, suggesting more complete and more reliable evidence.This article is part of a discussion meeting issue 'The growing ubiquity of algorithms in society: implications, impacts and innovations'.},
	language = {eng},
	number = {2128},
	journal = {Philosophical Transactions. Series A, Mathematical, Physical, and Engineering Sciences},
	author = {Schuemie, Martijn J. and Ryan, Patrick B. and Hripcsak, George and Madigan, David and Suchard, Marc A.},
	month = sep,
	year = {2018},
	pmid = {30082302},
	pmcid = {PMC6107542},
	keywords = {observational research, medicine, publication bias, reproducibility},
	pages = {20170356},
	file = {Full Text:/Users/erik/Zotero/storage/LH9ZY92X/Schuemie et al. - 2018 - Improving reproducibility by using high-throughput.pdf:application/pdf},
}

@article{reps_design_2018,
	title = {Design and implementation of a standardized framework to generate and evaluate patient-level prediction models using observational healthcare data},
	volume = {25},
	issn = {1527-974X},
	doi = {10.1093/jamia/ocy032},
	abstract = {OBJECTIVE: To develop a conceptual prediction model framework containing standardized steps and describe the corresponding open-source software developed to consistently implement the framework across computational environments and observational healthcare databases to enable model sharing and reproducibility.
METHODS: Based on existing best practices we propose a 5 step standardized framework for: (1) transparently defining the problem; (2) selecting suitable datasets; (3) constructing variables from the observational data; (4) learning the predictive model; and (5) validating the model performance. We implemented this framework as open-source software utilizing the Observational Medical Outcomes Partnership Common Data Model to enable convenient sharing of models and reproduction of model evaluation across multiple observational datasets. The software implementation contains default covariates and classifiers but the framework enables customization and extension.
RESULTS: As a proof-of-concept, demonstrating the transparency and ease of model dissemination using the software, we developed prediction models for 21 different outcomes within a target population of people suffering from depression across 4 observational databases. All 84 models are available in an accessible online repository to be implemented by anyone with access to an observational database in the Common Data Model format.
CONCLUSIONS: The proof-of-concept study illustrates the framework's ability to develop reproducible models that can be readily shared and offers the potential to perform extensive external validation of models, and improve their likelihood of clinical uptake. In future work the framework will be applied to perform an "all-by-all" prediction analysis to assess the observational data prediction domain across numerous target populations, outcomes and time, and risk settings.},
	language = {eng},
	number = {8},
	journal = {Journal of the American Medical Informatics Association: JAMIA},
	author = {Reps, Jenna M. and Schuemie, Martijn J. and Suchard, Marc A. and Ryan, Patrick B. and Rijnbeek, Peter R.},
	month = aug,
	year = {2018},
	pmid = {29718407},
	pmcid = {PMC6077830},
	keywords = {Female, Humans, Male, Observational Studies as Topic, Adult, Datasets as Topic, Health Services Needs and Demand, Machine Learning, Models, Theoretical, Observation, Prognosis, Risk Assessment, Software, Treatment Outcome},
	pages = {969--975},
	file = {Full Text:/Users/erik/Zotero/storage/DUHG8JI5/Reps et al. - 2018 - Design and implementation of a standardized framew.pdf:application/pdf},
}

@misc{rao_cohortdiagnostics_2023,
	title = {{CohortDiagnostics}: phenotype evaluation across a network of observational data sources using population-level characterization},
	copyright = {© 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
	shorttitle = {{CohortDiagnostics}},
	url = {https://www.medrxiv.org/content/10.1101/2023.06.28.23291982v1},
	doi = {10.1101/2023.06.28.23291982},
	abstract = {Objective This paper introduces a novel framework for evaluating phenotype algorithms (PAs) using the open-source tool, Cohort Diagnostics.
Materials and Methods The method is based on several diagnostic criteria to evaluate a patient cohort returned by a PA. Diagnostics include estimates of incidence rate, index date entry code breakdown, and prevalence of all observed clinical events prior to, on, and after index date. We test our framework by evaluating one PA for systemic lupus erythematosus (SLE) and two PAs for Alzheimer’s disease (AD) across 10 different observational data sources.
Results By utilizing CohortDiagnostics, we found that the population-level characteristics of individuals in the cohort of SLE closely matched the disease’s anticipated clinical profile. Specifically, the incidence rate of SLE was consistently higher in occurrence among females. Moreover, expected clinical events like laboratory tests, treatments, and repeated diagnoses were also observed. For AD, although one PA identified considerably fewer patients, absence of notable differences in clinical characteristics between the two cohorts suggested similar specificity.
Discussion We provide a practical and data-driven approach to evaluate PAs, using two clinical diseases as examples, across a network of OMOP data sources. Cohort Diagnostics can ensure the subjects identified by a specific PA align with those intended for inclusion in a research study.
Conclusion Diagnostics based on large-scale population-level characterization can offer insights into the misclassification errors of PAs.},
	language = {en},
	urldate = {2024-08-09},
	publisher = {medRxiv},
	author = {Rao, Gowtham A. and Shoaibi, Azza and Makadia, Rupa and Hardin, Jill and Swerdel, Joel and Weaver, James and Voss, Erica A. and Conover, Mitchell M. and Fortin, Stephen and Sena, Anthony G. and Knoll, Chris and Hughes, Nigel and Gilbert, James P. and Blacketer, Clair and Andryc, Alan and DeFalco, Frank and Molinaro, Anthony and Reps, Jenna and Schuemie, Martijn J. and Ryan, Patrick B.},
	month = jun,
	year = {2023},
	note = {ISSN: 2329-1982
Pages: 2023.06.28.23291982},
	file = {Full Text PDF:/Users/erik/Zotero/storage/4BSQTQM2/Rao et al. - 2023 - CohortDiagnostics phenotype evaluation across a n.pdf:application/pdf},
}

@article{swerdel_phevaluator_2019,
	title = {{PheValuator}: {Development} and evaluation of a phenotype algorithm evaluator},
	volume = {97},
	issn = {1532-0480},
	shorttitle = {{PheValuator}},
	doi = {10.1016/j.jbi.2019.103258},
	abstract = {BACKGROUND: The primary approach for defining disease in observational healthcare databases is to construct phenotype algorithms (PAs), rule-based heuristics predicated on the presence, absence, and temporal logic of clinical observations. However, a complete evaluation of PAs, i.e., determining sensitivity, specificity, and positive predictive value (PPV), is rarely performed. In this study, we propose a tool (PheValuator) to efficiently estimate a complete PA evaluation.
METHODS: We used 4 administrative claims datasets: OptumInsight's de-identified Clinformatics™ Datamart (Eden Prairie,MN); IBM MarketScan Multi-State Medicaid); IBM MarketScan Medicare Supplemental Beneficiaries; and IBM MarketScan Commercial Claims and Encounters from 2000 to 2017. Using PheValuator involves (1) creating a diagnostic predictive model for the phenotype, (2) applying the model to a large set of randomly selected subjects, and (3) comparing each subject's predicted probability for the phenotype to inclusion/exclusion in PAs. We used the predictions as a 'probabilistic gold standard' measure to classify positive/negative cases. We examined 4 phenotypes: myocardial infarction, cerebral infarction, chronic kidney disease, and atrial fibrillation. We examined several PAs for each phenotype including 1-time (1X) occurrence of the diagnosis code in the subject's record and 1-time occurrence of the diagnosis in an inpatient setting with the diagnosis code as the primary reason for admission (1X-IP-1stPos).
RESULTS: Across phenotypes, the 1X PA showed the highest sensitivity/lowest PPV among all PAs. 1X-IP-1stPos yielded the highest PPV/lowest sensitivity. Specificity was very high across algorithms. We found similar results between algorithms across datasets.
CONCLUSION: PheValuator appears to show promise as a tool to estimate PA performance characteristics.},
	language = {eng},
	journal = {Journal of Biomedical Informatics},
	author = {Swerdel, Joel N. and Hripcsak, George and Ryan, Patrick B.},
	month = sep,
	year = {2019},
	pmid = {31369862},
	pmcid = {PMC7736922},
	keywords = {Algorithms, Atrial Fibrillation, Cerebral Infarction, Computational Biology, Current Procedural Terminology, Databases, Factual, Diagnosis, Computer-Assisted, Diagnostic Errors, Diagnostic predictive modeling, Humans, Models, Statistical, Myocardial Infarction, Phenotype, Phenotype algorithms, Predictive Value of Tests, Probability, Renal Insufficiency, Chronic, Sensitivity and Specificity, Validation},
	pages = {103258},
	file = {Accepted Version:/Users/erik/Zotero/storage/AVKWJJJ9/Swerdel et al. - 2019 - PheValuator Development and evaluation of a pheno.pdf:application/pdf},
}

@article{swerdel_phevaluator_2022,
	title = {{PheValuator} 2.0: {Methodological} improvements for the {PheValuator} approach to semi-automated phenotype algorithm evaluation},
	volume = {135},
	issn = {1532-0480},
	shorttitle = {{PheValuator} 2.0},
	doi = {10.1016/j.jbi.2022.104177},
	abstract = {PURPOSE: Phenotype algorithms are central to performing analyses using observational data. These algorithms translate the clinical idea of a health condition into an executable set of rules allowing for queries of data elements from a database. PheValuator, a software package in the Observational Health Data Sciences and Informatics (OHDSI) tool stack, provides a method to assess the performance characteristics of these algorithms, namely, sensitivity, specificity, and positive and negative predictive value. It uses machine learning to develop predictive models for determining a probabilistic gold standard of subjects for assessment of cases and non-cases of health conditions. PheValuator was developed to complement or even replace the traditional approach of algorithm validation, i.e., by expert assessment of subject records through chart review. Results in our first PheValuator paper suggest a systematic underestimation of the PPV compared to previous results using chart review. In this paper we evaluate modifications made to the method designed to improve its performance.
METHODS: The major changes to PheValuator included allowing all diagnostic conditions, clinical observations, drug prescriptions, and laboratory measurements to be included as predictors within the modeling process whereas in the prior version there were significant restrictions on the included predictors. We also have allowed for the inclusion of the temporal relationships of the predictors in the model. To evaluate the performance of the new method, we compared the results from the new and original methods against results found from the literature using traditional validation of algorithms for 19 phenotypes. We performed these tests using data from five commercial databases.
RESULTS: In the assessment aggregating all phenotype algorithms, the median difference between the PheValuator estimate and the gold standard estimate for PPV was reduced from -21 (IQR -34, -3) in Version 1.0 to 4 (IQR -3, 15) using Version 2.0. We found a median difference in specificity of 3 (IQR 1, 4.25) for Version 1.0 and 3 (IQR 1, 4) for Version 2.0. The median difference between the two versions of PheValuator and the gold standard for estimates of sensitivity was reduced from -39 (-51, -20) to -16 (-34, -6).
CONCLUSION: PheValuator 2.0 produces estimates for the performance characteristics for phenotype algorithms that are significantly closer to estimates from traditional validation through chart review compared to version 1.0. With this tool in researcher's toolkits, methods, such as quantitative bias analysis, may now be used to improve the reliability and reproducibility of research studies using observational data.},
	language = {eng},
	journal = {Journal of Biomedical Informatics},
	author = {Swerdel, Joel N. and Schuemie, Martijn and Murray, Gayle and Ryan, Patrick B.},
	month = nov,
	year = {2022},
	pmid = {35995107},
	keywords = {Algorithms, Databases, Factual, Machine Learning, Phenotype, Phenotype algorithms, Positive predictive value, Reproducibility of Results, Sensitivity, Specificity},
	pages = {104177},
}

@Manual{ushey_renv_2024,
  title = {renv: Project Environments},
  author = {Kevin Ushey and Hadley Wickham},
  year = {2024},
  note = {R package version 1.0.7, https://github.com/rstudio/renv},
  url = {https://rstudio.github.io/renv/},
}